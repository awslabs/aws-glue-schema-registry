[2021-06-11 00:41:10,083] INFO StandaloneConfig values: 
	cluster = connect
	rest.advertised.host.name = null
	task.shutdown.graceful.timeout.ms = 5000
	rest.host.name = 127.0.0.1
	rest.advertised.port = null
	bootstrap.servers = [127.0.0.1:9092]
	offset.flush.timeout.ms = 5000
	offset.flush.interval.ms = 10000
	rest.port = 8086
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	access.control.allow.methods = 
	access.control.allow.origin = 
	offset.storage.file.filename = standalone.offsets
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:178)
[2021-06-11 00:41:10,946] INFO Logging initialized @2482ms (org.eclipse.jetty.util.log:186)
[2021-06-11 00:41:12,243] INFO AWSKafkaAvroConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverterConfig:178)
[2021-06-11 00:41:12,245] INFO Configuring Amazon Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:77)
[2021-06-11 00:41:12,308] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,310] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,316] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,322] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,323] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,325] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,327] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,329] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 00:41:12,331] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,334] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,335] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 00:41:12,338] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:12,345] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 00:41:15,084] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.avro.AWSKafkaAvroDeserializer:80)
[2021-06-11 00:41:15,090] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,091] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,092] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,094] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,096] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,097] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,098] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,099] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 00:41:15,101] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,111] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,112] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 00:41:15,113] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:41:15,114] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 00:41:15,423] INFO AvroDataConfig values: 
	schemas.cache.config = 1000
	enhanced.avro.schema.support = false
	connect.meta.data = true
 (com.amazonaws.services.schemaregistry.kafkaconnect.avrodata.AvroDataConfig:178)
[2021-06-11 00:41:15,497] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-11 00:41:15,505] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-11 00:41:15,507] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-11 00:41:15,576] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-11 00:41:15,725] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-11 00:41:15,735] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-11 00:41:15,736] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-11 00:41:15,740] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-11 00:41:15,748] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-11 00:41:15,751] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-11 00:41:15,752] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-11 00:41:16,526] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
Jun 11, 2021 12:41:20 AM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-11 00:41:20,605] INFO Started o.e.j.s.ServletContextHandler@72458efc{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-11 00:41:20,702] INFO Started ServerConnector@353357fe{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-11 00:41:20,705] INFO Started @12252ms (org.eclipse.jetty.server.Server:379)
[2021-06-11 00:41:20,707] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-11 00:41:20,708] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-11 00:41:20,724] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-11 00:41:20,750] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 00:41:20,762] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 00:41:20,790] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 00:41:20,795] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:178)
[2021-06-11 00:41:20,835] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-11 00:41:20,837] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 00:41:20,838] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 00:41:20,870] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-11 00:41:20,917] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 00:41:20,946] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-11 00:41:23,160] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-11 00:41:24,116] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 00:41:24,737] INFO Opened connection [connectionId{localValue:1, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 00:41:24,967] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 5]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=137464200, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Fri Jun 11 00:41:15 GMT 2021, lastUpdateTimeNanos=618206043471622} (org.mongodb.driver.cluster:71)
[2021-06-11 00:41:26,940] INFO Opened connection [connectionId{localValue:2, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 00:41:28,338] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-11 00:41:28,356] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-11 00:41:28,371] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-11 00:41:28,974] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-11 00:41:28,975] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-11 00:41:28,978] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 00:41:28,998] INFO Resuming the change stream after the previous offset: {"_data": "8260C2B135000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-11 00:41:29,383] INFO Reflections took 13284 ms to scan 65 urls, producing 5663 keys and 43576 values  (org.reflections.Reflections:229)
[2021-06-11 00:41:30,980] INFO Reflections took 10015 ms to scan 65 urls, producing 5663 keys and 43576 values  (org.reflections.Reflections:229)
[2021-06-11 00:41:30,987] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 00:41:30,990] INFO Instantiated connector file-sink-standalone with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 00:41:30,991] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 00:41:30,993] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	topics = [gsr.connect.avro.test.fruits]
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:178)
[2021-06-11 00:41:31,012] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-11 00:41:31,014] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 00:41:31,016] INFO Instantiated task file-sink-standalone-0 with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 00:41:31,065] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-11 00:41:31,111] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-11 00:41:31,230] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-11 00:41:31,233] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-11 00:41:31,242] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 00:41:31,249] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-11 00:41:31,830] WARN Error while fetching metadata with correlation id 1 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 00:41:31,864] WARN Error while fetching metadata with correlation id 2 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 00:41:31,975] WARN Error while fetching metadata with correlation id 4 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 00:41:32,128] WARN Error while fetching metadata with correlation id 6 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 00:41:32,289] WARN Error while fetching metadata with correlation id 8 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 00:41:32,452] WARN Error while fetching metadata with correlation id 10 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 00:41:34,186] INFO Discovered coordinator localhost:9092 (id: 2147483646 rack: null) for group connect-file-sink-standalone. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:505)
[2021-06-11 00:41:34,189] INFO Revoking previously assigned partitions [] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:280)
[2021-06-11 00:41:34,191] INFO (Re-)joining group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:326)
[2021-06-11 00:41:34,492] INFO Successfully joined group connect-file-sink-standalone with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:434)
[2021-06-11 00:41:34,495] INFO Setting newly assigned partitions [gsr.connect.avro.test.fruits-0] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:219)
[2021-06-11 00:41:34,522] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 00:41:37,316] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 00:41:37,469] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 00:41:37,477] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 00:41:37,490] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 00:41:37,493] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 00:41:40,876] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 61 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-11 00:41:41,030] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 00:41:51,067] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:04:04,131] INFO StandaloneConfig values: 
	cluster = connect
	rest.advertised.host.name = null
	task.shutdown.graceful.timeout.ms = 5000
	rest.host.name = 127.0.0.1
	rest.advertised.port = null
	bootstrap.servers = [127.0.0.1:9092]
	offset.flush.timeout.ms = 5000
	offset.flush.interval.ms = 10000
	rest.port = 8086
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	access.control.allow.methods = 
	access.control.allow.origin = 
	offset.storage.file.filename = standalone.offsets
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:178)
[2021-06-11 18:04:04,820] INFO Logging initialized @2617ms (org.eclipse.jetty.util.log:186)
[2021-06-11 18:04:05,719] INFO AWSKafkaAvroConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverterConfig:178)
[2021-06-11 18:04:05,721] INFO Configuring Amazon Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:77)
[2021-06-11 18:04:05,755] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,756] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,759] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,763] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,764] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,765] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,767] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,768] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 18:04:05,769] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,770] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,771] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 18:04:05,773] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:05,776] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 18:04:08,322] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.avro.AWSKafkaAvroDeserializer:80)
[2021-06-11 18:04:08,329] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,333] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,335] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,336] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,339] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,340] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,342] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,344] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 18:04:08,347] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,353] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,355] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 18:04:08,357] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:04:08,361] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 18:04:08,606] INFO AvroDataConfig values: 
	schemas.cache.config = 1000
	enhanced.avro.schema.support = false
	connect.meta.data = true
 (com.amazonaws.services.schemaregistry.kafkaconnect.avrodata.AvroDataConfig:178)
[2021-06-11 18:04:08,657] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-11 18:04:08,664] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-11 18:04:08,665] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-11 18:04:08,713] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-11 18:04:08,855] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-11 18:04:08,864] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-11 18:04:08,865] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-11 18:04:08,867] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-11 18:04:08,874] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-11 18:04:08,876] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-11 18:04:08,878] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-11 18:04:09,414] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
Jun 11, 2021 6:04:19 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-11 18:04:19,561] INFO Started o.e.j.s.ServletContextHandler@301d8120{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-11 18:04:19,606] INFO Started ServerConnector@1c12f3ee{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-11 18:04:19,607] INFO Started @17422ms (org.eclipse.jetty.server.Server:379)
[2021-06-11 18:04:19,609] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-11 18:04:19,613] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-11 18:04:19,618] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-11 18:04:19,625] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 18:04:19,630] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 18:04:19,637] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 18:04:19,640] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:178)
[2021-06-11 18:04:19,682] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-11 18:04:19,685] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 18:04:19,687] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 18:04:19,719] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-11 18:04:19,719] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 18:04:19,728] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-11 18:04:20,665] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-11 18:04:21,183] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 18:04:21,372] INFO Opened connection [connectionId{localValue:1, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 18:04:21,415] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16432913, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Fri Jun 11 18:04:16 GMT 2021, lastUpdateTimeNanos=3475973218691} (org.mongodb.driver.cluster:71)
[2021-06-11 18:04:21,711] INFO Opened connection [connectionId{localValue:2, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 18:04:22,815] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-11 18:04:22,834] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-11 18:04:22,835] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-11 18:04:23,096] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-11 18:04:23,110] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-11 18:04:23,112] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 18:04:23,117] INFO Resuming the change stream after the previous offset: {"_data": "8260C3A5A0000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-11 18:04:26,720] INFO Reflections took 17612 ms to scan 65 urls, producing 5709 keys and 43863 values  (org.reflections.Reflections:229)
[2021-06-11 18:04:28,219] INFO Reflections took 8474 ms to scan 65 urls, producing 5709 keys and 43863 values  (org.reflections.Reflections:229)
[2021-06-11 18:04:28,229] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 18:04:28,232] INFO Instantiated connector file-sink-standalone with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 18:04:28,234] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 18:04:28,236] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	topics = [gsr.connect.avro.test.fruits]
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:178)
[2021-06-11 18:04:28,243] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-11 18:04:28,246] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 18:04:28,248] INFO Instantiated task file-sink-standalone-0 with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 18:04:28,302] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-11 18:04:28,356] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-11 18:04:28,491] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-11 18:04:28,492] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-11 18:04:28,499] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 18:04:28,511] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-11 18:04:28,913] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 18:04:29,598] WARN Error while fetching metadata with correlation id 1 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:29,766] WARN Error while fetching metadata with correlation id 2 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:29,897] WARN Error while fetching metadata with correlation id 4 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:30,020] WARN Error while fetching metadata with correlation id 6 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:30,281] WARN Error while fetching metadata with correlation id 8 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:30,655] WARN Error while fetching metadata with correlation id 10 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:30,882] WARN Error while fetching metadata with correlation id 12 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:31,040] WARN Error while fetching metadata with correlation id 14 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:31,161] WARN Error while fetching metadata with correlation id 16 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:31,284] WARN Error while fetching metadata with correlation id 18 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:31,418] WARN Error while fetching metadata with correlation id 20 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:04:32,867] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 18:04:33,035] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 18:04:33,038] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 18:04:33,041] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 18:04:33,044] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 18:04:33,565] INFO Discovered coordinator localhost:9092 (id: 2147483646 rack: null) for group connect-file-sink-standalone. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:505)
[2021-06-11 18:04:33,568] INFO Revoking previously assigned partitions [] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:280)
[2021-06-11 18:04:33,570] INFO (Re-)joining group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:326)
[2021-06-11 18:04:33,749] INFO Successfully joined group connect-file-sink-standalone with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:434)
[2021-06-11 18:04:33,754] INFO Setting newly assigned partitions [gsr.connect.avro.test.fruits-0] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:219)
[2021-06-11 18:04:38,269] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:04:39,748] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 25 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-11 18:04:48,287] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:04:58,274] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:06:52,627] INFO StandaloneConfig values: 
	cluster = connect
	rest.advertised.host.name = null
	task.shutdown.graceful.timeout.ms = 5000
	rest.host.name = 127.0.0.1
	rest.advertised.port = null
	bootstrap.servers = [127.0.0.1:9092]
	offset.flush.timeout.ms = 5000
	offset.flush.interval.ms = 10000
	rest.port = 8086
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	access.control.allow.methods = 
	access.control.allow.origin = 
	offset.storage.file.filename = standalone.offsets
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:178)
[2021-06-11 18:06:53,203] INFO Logging initialized @2234ms (org.eclipse.jetty.util.log:186)
[2021-06-11 18:06:54,081] INFO AWSKafkaAvroConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverterConfig:178)
[2021-06-11 18:06:54,083] INFO Configuring Amazon Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:77)
[2021-06-11 18:06:54,104] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,105] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,109] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,113] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,114] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,115] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,117] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,118] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 18:06:54,119] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,120] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,121] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 18:06:54,123] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:54,127] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 18:06:56,473] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.avro.AWSKafkaAvroDeserializer:80)
[2021-06-11 18:06:56,477] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,478] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,479] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,481] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,482] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,483] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,484] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,485] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 18:06:56,487] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,496] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,497] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 18:06:56,499] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:06:56,501] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 18:06:56,715] INFO AvroDataConfig values: 
	schemas.cache.config = 1000
	enhanced.avro.schema.support = false
	connect.meta.data = true
 (com.amazonaws.services.schemaregistry.kafkaconnect.avrodata.AvroDataConfig:178)
[2021-06-11 18:06:56,763] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-11 18:06:56,768] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-11 18:06:56,769] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-11 18:06:56,808] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-11 18:06:56,942] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-11 18:06:56,951] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-11 18:06:56,951] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-11 18:06:56,954] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-11 18:06:56,962] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-11 18:06:56,964] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-11 18:06:56,965] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-11 18:06:57,548] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
Jun 11, 2021 6:07:00 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-11 18:07:00,088] INFO Started o.e.j.s.ServletContextHandler@301d8120{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-11 18:07:00,120] INFO Started ServerConnector@10fe727b{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-11 18:07:00,121] INFO Started @9161ms (org.eclipse.jetty.server.Server:379)
[2021-06-11 18:07:00,122] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-11 18:07:00,123] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-11 18:07:00,129] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-11 18:07:00,135] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 18:07:00,139] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 18:07:00,147] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 18:07:00,156] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:178)
[2021-06-11 18:07:00,174] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-11 18:07:00,175] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 18:07:00,176] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 18:07:00,203] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 18:07:00,203] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-11 18:07:00,209] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-11 18:07:01,131] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-11 18:07:01,517] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 18:07:01,586] INFO Opened connection [connectionId{localValue:1, serverValue:21}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 18:07:01,669] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=35947262, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Fri Jun 11 18:06:47 GMT 2021, lastUpdateTimeNanos=3636202228862} (org.mongodb.driver.cluster:71)
[2021-06-11 18:07:02,065] INFO Opened connection [connectionId{localValue:2, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 18:07:03,185] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-11 18:07:03,200] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-11 18:07:03,202] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-11 18:07:03,502] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-11 18:07:03,513] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-11 18:07:03,514] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 18:07:03,520] INFO Resuming the change stream after the previous offset: {"_data": "8260C3A637000000042B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-11 18:07:05,884] INFO Reflections took 8640 ms to scan 65 urls, producing 5709 keys and 43863 values  (org.reflections.Reflections:229)
[2021-06-11 18:07:06,262] INFO Reflections took 6043 ms to scan 65 urls, producing 5709 keys and 43863 values  (org.reflections.Reflections:229)
[2021-06-11 18:07:06,267] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 18:07:06,268] INFO Instantiated connector file-sink-standalone with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 18:07:06,270] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 18:07:06,272] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	topics = [gsr.connect.avro.test.fruits]
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:178)
[2021-06-11 18:07:06,276] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-11 18:07:06,277] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 18:07:06,279] INFO Instantiated task file-sink-standalone-0 with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 18:07:06,299] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-11 18:07:06,315] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-11 18:07:06,385] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-11 18:07:06,387] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-11 18:07:06,391] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 18:07:06,399] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-11 18:07:06,887] WARN Error while fetching metadata with correlation id 1 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:07:06,974] WARN Error while fetching metadata with correlation id 2 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:07:07,168] WARN Error while fetching metadata with correlation id 4 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:07:07,330] WARN Error while fetching metadata with correlation id 6 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:07:07,443] WARN Error while fetching metadata with correlation id 8 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 18:07:08,801] INFO Discovered coordinator localhost:9092 (id: 2147483646 rack: null) for group connect-file-sink-standalone. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:505)
[2021-06-11 18:07:08,803] INFO Revoking previously assigned partitions [] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:280)
[2021-06-11 18:07:08,805] INFO (Re-)joining group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:326)
[2021-06-11 18:07:08,991] INFO Successfully joined group connect-file-sink-standalone with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:434)
[2021-06-11 18:07:08,996] INFO Setting newly assigned partitions [gsr.connect.avro.test.fruits-0] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:219)
[2021-06-11 18:07:09,276] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 18:07:11,130] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 18:07:11,225] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 18:07:11,232] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 18:07:11,234] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 18:07:11,235] INFO Schema Version Id received from the from schema registry: d09441e7-992c-4930-9bf6-bf8484da58d9 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 18:07:16,287] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:07:20,236] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 39 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-11 18:07:26,304] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:07:36,293] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:07:46,289] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 19:03:27,899] INFO StandaloneConfig values: 
	cluster = connect
	rest.advertised.host.name = null
	task.shutdown.graceful.timeout.ms = 5000
	rest.host.name = 127.0.0.1
	rest.advertised.port = null
	bootstrap.servers = [127.0.0.1:9092]
	offset.flush.timeout.ms = 5000
	offset.flush.interval.ms = 10000
	rest.port = 8086
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	access.control.allow.methods = 
	access.control.allow.origin = 
	offset.storage.file.filename = standalone.offsets
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:178)
[2021-06-11 19:03:28,466] INFO Logging initialized @1469ms (org.eclipse.jetty.util.log:186)
[2021-06-11 19:03:29,219] INFO AWSKafkaAvroConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverterConfig:178)
[2021-06-11 19:03:29,221] INFO Configuring Amazon Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:77)
[2021-06-11 19:03:29,238] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,239] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,242] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,246] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,247] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,249] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,251] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,252] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 19:03:29,253] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,254] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,255] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 19:03:29,256] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:29,258] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 19:03:32,023] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.avro.AWSKafkaAvroDeserializer:80)
[2021-06-11 19:03:32,028] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,029] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,031] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,033] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,034] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,036] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,037] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,038] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 19:03:32,041] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,047] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,048] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 19:03:32,050] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:03:32,053] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 19:03:32,240] INFO AvroDataConfig values: 
	schemas.cache.config = 1000
	enhanced.avro.schema.support = false
	connect.meta.data = true
 (com.amazonaws.services.schemaregistry.kafkaconnect.avrodata.AvroDataConfig:178)
[2021-06-11 19:03:32,286] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-11 19:03:32,288] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-11 19:03:32,289] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-11 19:03:32,323] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-11 19:03:32,465] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-11 19:03:32,472] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-11 19:03:32,473] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-11 19:03:32,475] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-11 19:03:32,479] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-11 19:03:32,482] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-11 19:03:32,483] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-11 19:03:32,849] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
Jun 11, 2021 7:03:34 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-11 19:03:34,841] INFO Started o.e.j.s.ServletContextHandler@2e3a5237{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-11 19:03:34,871] INFO Started ServerConnector@661a5859{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-11 19:03:34,872] INFO Started @7888ms (org.eclipse.jetty.server.Server:379)
[2021-06-11 19:03:34,873] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-11 19:03:34,874] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-11 19:03:34,880] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-11 19:03:34,887] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 19:03:34,891] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 19:03:34,902] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 19:03:34,904] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:178)
[2021-06-11 19:03:34,921] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-11 19:03:34,922] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 19:03:34,923] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 19:03:34,953] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-11 19:03:34,954] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 19:03:34,958] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-11 19:03:35,713] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-11 19:03:36,065] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 19:03:36,090] INFO Opened connection [connectionId{localValue:1, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 19:03:36,152] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=12615214, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Fri Jun 11 19:03:32 GMT 2021, lastUpdateTimeNanos=7030706503329} (org.mongodb.driver.cluster:71)
[2021-06-11 19:03:36,517] INFO Opened connection [connectionId{localValue:2, serverValue:24}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 19:03:37,617] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-11 19:03:37,626] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-11 19:03:37,627] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-11 19:03:37,874] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-11 19:03:37,875] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-11 19:03:37,877] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 19:03:37,886] INFO Resuming the change stream after the previous offset: {"_data": "8260C3B384000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-11 19:03:40,692] INFO Reflections took 8043 ms to scan 67 urls, producing 5709 keys and 43863 values  (org.reflections.Reflections:229)
[2021-06-11 19:03:41,025] INFO Reflections took 6062 ms to scan 67 urls, producing 5709 keys and 43863 values  (org.reflections.Reflections:229)
[2021-06-11 19:03:41,028] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 19:03:41,029] INFO Instantiated connector file-sink-standalone with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 19:03:41,031] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 19:03:41,032] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	topics = [gsr.connect.avro.test.fruits]
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:178)
[2021-06-11 19:03:41,037] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-11 19:03:41,038] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 19:03:41,039] INFO Instantiated task file-sink-standalone-0 with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 19:03:41,059] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-11 19:03:41,072] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-11 19:03:41,151] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-11 19:03:41,152] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-11 19:03:41,156] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 19:03:41,159] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-11 19:03:41,563] WARN Error while fetching metadata with correlation id 1 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 19:03:41,644] WARN Error while fetching metadata with correlation id 2 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 19:03:41,769] WARN Error while fetching metadata with correlation id 4 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 19:03:41,890] WARN Error while fetching metadata with correlation id 6 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 19:03:42,013] WARN Error while fetching metadata with correlation id 8 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-11 19:03:42,956] INFO Discovered coordinator localhost:9092 (id: 2147483646 rack: null) for group connect-file-sink-standalone. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:505)
[2021-06-11 19:03:42,958] INFO Revoking previously assigned partitions [] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:280)
[2021-06-11 19:03:42,960] INFO (Re-)joining group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:326)
[2021-06-11 19:03:43,105] INFO Successfully joined group connect-file-sink-standalone with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:434)
[2021-06-11 19:03:43,109] INFO Setting newly assigned partitions [gsr.connect.avro.test.fruits-0] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:219)
[2021-06-11 19:03:43,666] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 19:03:46,414] INFO Registered the schema version with schema version id = 1e8c757e-04fd-4dcf-8b11-824cc0645550 and with version number = 3 and status AVAILABLE (com.amazonaws.services.schemaregistry.common.AWSSchemaRegistryClient:341)
[2021-06-11 19:03:46,963] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 19:03:47,026] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 19:03:47,031] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 19:03:47,033] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-11 19:03:47,034] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-11 19:03:51,048] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 19:03:54,980] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 42 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-11 19:04:01,061] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 19:04:11,052] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 19:04:21,053] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 17:06:03,298] INFO StandaloneConfig values: 
	cluster = connect
	rest.advertised.host.name = null
	task.shutdown.graceful.timeout.ms = 5000
	rest.host.name = 127.0.0.1
	rest.advertised.port = null
	bootstrap.servers = [127.0.0.1:9092]
	offset.flush.timeout.ms = 5000
	offset.flush.interval.ms = 10000
	rest.port = 8086
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	access.control.allow.methods = 
	access.control.allow.origin = 
	offset.storage.file.filename = standalone.offsets
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:178)
[2021-06-15 17:06:04,351] INFO Logging initialized @3940ms (org.eclipse.jetty.util.log:186)
[2021-06-15 17:06:05,898] INFO AWSKafkaAvroConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverterConfig:178)
[2021-06-15 17:06:05,902] INFO Configuring Amazon Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:77)
[2021-06-15 17:06:05,953] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,954] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,958] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,968] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,970] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,972] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,978] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,979] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 17:06:05,982] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,984] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,985] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 17:06:05,986] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:05,991] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 17:06:09,602] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.avro.AWSKafkaAvroDeserializer:80)
[2021-06-15 17:06:09,637] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,646] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,659] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,667] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,674] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,678] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,687] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,689] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 17:06:09,691] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,707] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,716] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 17:06:09,722] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:06:09,728] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 17:06:10,200] INFO AvroDataConfig values: 
	schemas.cache.config = 1000
	enhanced.avro.schema.support = false
	connect.meta.data = true
 (com.amazonaws.services.schemaregistry.kafkaconnect.avrodata.AvroDataConfig:178)
[2021-06-15 17:06:10,290] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-15 17:06:10,292] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-15 17:06:10,296] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-15 17:06:10,408] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-15 17:06:10,849] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-15 17:06:10,861] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-15 17:06:10,869] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-15 17:06:10,884] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-15 17:06:10,904] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-15 17:06:10,908] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-15 17:06:10,909] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-15 17:06:12,683] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
Jun 15, 2021 5:06:16 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-15 17:06:16,821] INFO Started o.e.j.s.ServletContextHandler@2e3a5237{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-15 17:06:16,912] INFO Started ServerConnector@66f11697{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-15 17:06:16,914] INFO Started @16559ms (org.eclipse.jetty.server.Server:379)
[2021-06-15 17:06:16,917] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-15 17:06:16,918] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-15 17:06:16,932] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-15 17:06:16,954] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 17:06:16,999] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 17:06:17,026] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 17:06:17,031] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:178)
[2021-06-15 17:06:17,088] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-15 17:06:17,091] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 17:06:17,092] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 17:06:17,139] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-15 17:06:17,150] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 17:06:17,156] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-15 17:06:18,733] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-15 17:06:19,543] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 17:06:20,186] INFO Opened connection [connectionId{localValue:1, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 17:06:20,452] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=85285600, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Tue Jun 15 17:06:12 GMT 2021, lastUpdateTimeNanos=82462864949571} (org.mongodb.driver.cluster:71)
[2021-06-15 17:06:22,360] INFO Opened connection [connectionId{localValue:2, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 17:06:23,647] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-15 17:06:23,668] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-15 17:06:23,670] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-15 17:06:24,232] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-15 17:06:24,233] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-15 17:06:24,243] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 17:06:24,262] INFO Resuming the change stream after the previous offset: {"_data": "8260C8DE0E000000012B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-15 17:06:27,072] INFO Reflections took 15116 ms to scan 67 urls, producing 5722 keys and 43968 values  (org.reflections.Reflections:229)
[2021-06-15 17:06:29,327] INFO Reflections took 12160 ms to scan 67 urls, producing 5722 keys and 43968 values  (org.reflections.Reflections:229)
[2021-06-15 17:06:29,331] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 17:06:29,341] INFO Instantiated connector file-sink-standalone with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 17:06:29,343] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 17:06:29,354] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	topics = [gsr.connect.avro.test.fruits]
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:178)
[2021-06-15 17:06:29,364] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-15 17:06:29,366] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 17:06:29,367] INFO Instantiated task file-sink-standalone-0 with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 17:06:29,411] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-15 17:06:29,444] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-15 17:06:29,593] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-15 17:06:29,595] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-15 17:06:29,605] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 17:06:29,623] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-15 17:06:29,806] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 17:06:30,654] WARN Error while fetching metadata with correlation id 1 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:30,725] WARN Error while fetching metadata with correlation id 2 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:30,862] WARN Error while fetching metadata with correlation id 4 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:30,984] WARN Error while fetching metadata with correlation id 6 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:31,112] WARN Error while fetching metadata with correlation id 8 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:31,628] WARN Error while fetching metadata with correlation id 10 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:31,950] WARN Error while fetching metadata with correlation id 12 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:32,181] WARN Error while fetching metadata with correlation id 14 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:32,309] WARN Error while fetching metadata with correlation id 16 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 17:06:34,550] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 17:06:34,984] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 17:06:34,987] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 17:06:34,995] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 17:06:34,997] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 17:06:36,072] INFO Discovered coordinator localhost:9092 (id: 2147483646 rack: null) for group connect-file-sink-standalone. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:505)
[2021-06-15 17:06:36,083] INFO Revoking previously assigned partitions [] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:280)
[2021-06-15 17:06:36,086] INFO (Re-)joining group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:326)
[2021-06-15 17:06:36,323] INFO Successfully joined group connect-file-sink-standalone with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:434)
[2021-06-15 17:06:36,330] INFO Setting newly assigned partitions [gsr.connect.avro.test.fruits-0] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:219)
[2021-06-15 17:06:37,188] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 52 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-15 17:06:39,385] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 17:06:49,432] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 17:06:59,392] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 18:10:48,141] INFO StandaloneConfig values: 
	cluster = connect
	rest.advertised.host.name = null
	task.shutdown.graceful.timeout.ms = 5000
	rest.host.name = 127.0.0.1
	rest.advertised.port = null
	bootstrap.servers = [127.0.0.1:9092]
	offset.flush.timeout.ms = 5000
	offset.flush.interval.ms = 10000
	rest.port = 8086
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	access.control.allow.methods = 
	access.control.allow.origin = 
	offset.storage.file.filename = standalone.offsets
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:178)
[2021-06-15 18:10:49,249] INFO Logging initialized @2253ms (org.eclipse.jetty.util.log:186)
[2021-06-15 18:10:51,415] INFO AWSKafkaAvroConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverterConfig:178)
[2021-06-15 18:10:51,420] INFO Configuring Amazon Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:77)
[2021-06-15 18:10:51,474] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,476] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,482] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,490] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,491] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,494] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,496] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,498] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 18:10:51,502] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,504] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,506] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 18:10:51,508] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:51,515] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 18:10:56,610] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.avro.AWSKafkaAvroDeserializer:80)
[2021-06-15 18:10:56,617] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,619] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,624] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,626] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,627] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,632] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,635] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,637] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 18:10:56,645] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,657] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,661] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 18:10:56,663] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:10:56,665] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 18:10:57,083] INFO AvroDataConfig values: 
	schemas.cache.config = 1000
	enhanced.avro.schema.support = false
	connect.meta.data = true
 (com.amazonaws.services.schemaregistry.kafkaconnect.avrodata.AvroDataConfig:178)
[2021-06-15 18:10:57,161] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-15 18:10:57,165] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-15 18:10:57,209] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-15 18:10:57,351] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-15 18:10:57,657] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-15 18:10:57,813] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-15 18:10:57,815] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-15 18:10:57,818] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-15 18:10:57,831] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-15 18:10:57,835] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-15 18:10:57,837] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-15 18:10:59,417] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
Jun 15, 2021 6:11:04 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-15 18:11:04,139] INFO Started o.e.j.s.ServletContextHandler@2e3a5237{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-15 18:11:04,231] INFO Started ServerConnector@66f11697{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-15 18:11:04,233] INFO Started @17247ms (org.eclipse.jetty.server.Server:379)
[2021-06-15 18:11:04,235] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-15 18:11:04,237] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-15 18:11:04,253] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-15 18:11:04,269] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 18:11:04,321] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 18:11:04,344] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 18:11:04,351] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:178)
[2021-06-15 18:11:04,415] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-15 18:11:04,417] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 18:11:04,419] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 18:11:04,472] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-15 18:11:04,518] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 18:11:04,524] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-15 18:11:06,943] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-15 18:11:07,487] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 18:11:07,797] INFO Opened connection [connectionId{localValue:1, serverValue:21}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 18:11:07,971] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=123142100, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Tue Jun 15 18:11:01 GMT 2021, lastUpdateTimeNanos=86354871779471} (org.mongodb.driver.cluster:71)
[2021-06-15 18:11:08,404] INFO Opened connection [connectionId{localValue:2, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 18:11:09,573] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-15 18:11:09,591] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-15 18:11:09,622] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-15 18:11:10,146] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-15 18:11:10,148] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-15 18:11:10,150] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 18:11:10,170] INFO Resuming the change stream after the previous offset: {"_data": "8260C8ED35000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-15 18:11:11,635] INFO Reflections took 13182 ms to scan 67 urls, producing 5722 keys and 43968 values  (org.reflections.Reflections:229)
[2021-06-15 18:11:12,810] INFO Reflections took 8253 ms to scan 67 urls, producing 5722 keys and 43968 values  (org.reflections.Reflections:229)
[2021-06-15 18:11:12,815] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 18:11:12,817] INFO Instantiated connector file-sink-standalone with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 18:11:12,818] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 18:11:12,820] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	topics = [gsr.connect.avro.test.fruits]
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:178)
[2021-06-15 18:11:12,825] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-15 18:11:12,826] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 18:11:12,827] INFO Instantiated task file-sink-standalone-0 with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 18:11:12,854] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-15 18:11:12,877] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-15 18:11:12,969] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-15 18:11:12,970] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-15 18:11:12,978] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 18:11:12,983] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-15 18:11:13,430] WARN Error while fetching metadata with correlation id 1 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 18:11:13,497] WARN Error while fetching metadata with correlation id 2 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 18:11:13,627] WARN Error while fetching metadata with correlation id 4 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 18:11:13,760] WARN Error while fetching metadata with correlation id 6 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 18:11:13,903] WARN Error while fetching metadata with correlation id 8 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 18:11:14,026] WARN Error while fetching metadata with correlation id 10 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 18:11:15,298] INFO Discovered coordinator localhost:9092 (id: 2147483646 rack: null) for group connect-file-sink-standalone. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:505)
[2021-06-15 18:11:15,301] INFO Revoking previously assigned partitions [] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:280)
[2021-06-15 18:11:15,303] INFO (Re-)joining group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:326)
[2021-06-15 18:11:15,491] INFO Successfully joined group connect-file-sink-standalone with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:434)
[2021-06-15 18:11:15,495] INFO Setting newly assigned partitions [gsr.connect.avro.test.fruits-0] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:219)
[2021-06-15 18:11:15,659] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 18:11:18,330] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 18:11:18,450] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 18:11:18,452] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 18:11:18,454] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 18:11:18,455] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 18:11:22,840] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 18:11:24,497] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 26 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-15 18:11:32,865] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 18:11:42,843] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 23:00:06,512] INFO StandaloneConfig values: 
	cluster = connect
	rest.advertised.host.name = null
	task.shutdown.graceful.timeout.ms = 5000
	rest.host.name = 127.0.0.1
	rest.advertised.port = null
	bootstrap.servers = [127.0.0.1:9092]
	offset.flush.timeout.ms = 5000
	offset.flush.interval.ms = 10000
	rest.port = 8086
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	access.control.allow.methods = 
	access.control.allow.origin = 
	offset.storage.file.filename = standalone.offsets
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:178)
[2021-06-15 23:00:07,238] INFO Logging initialized @2432ms (org.eclipse.jetty.util.log:186)
[2021-06-15 23:00:08,460] INFO AWSKafkaAvroConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.AWSKafkaAvroConverterConfig:178)
[2021-06-15 23:00:08,462] INFO Configuring Amazon Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:77)
[2021-06-15 23:00:08,488] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,489] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,492] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,496] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,498] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,499] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,500] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,501] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 23:00:08,503] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,504] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,505] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 23:00:08,506] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:08,509] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 23:00:11,498] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.avro.AWSKafkaAvroDeserializer:80)
[2021-06-15 23:00:11,503] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,504] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,505] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,506] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,508] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,509] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,510] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,511] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 23:00:11,513] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,521] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,522] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 23:00:11,524] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:00:11,526] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 23:00:11,764] INFO AvroDataConfig values: 
	schemas.cache.config = 1000
	enhanced.avro.schema.support = false
	connect.meta.data = true
 (com.amazonaws.services.schemaregistry.kafkaconnect.avrodata.AvroDataConfig:178)
[2021-06-15 23:00:11,831] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-15 23:00:11,832] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-15 23:00:11,834] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-15 23:00:11,892] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-15 23:00:12,064] INFO ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 9223372036854775807
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 2147483647
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 2147483647
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 1
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0
 (org.apache.kafka.clients.producer.ProducerConfig:178)
[2021-06-15 23:00:12,079] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-15 23:00:12,081] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-15 23:00:12,086] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-15 23:00:12,097] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-15 23:00:12,101] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-15 23:00:12,105] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-15 23:00:12,908] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
Jun 15, 2021 11:00:16 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-15 23:00:16,279] INFO Started o.e.j.s.ServletContextHandler@2e3a5237{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-15 23:00:16,351] INFO Started ServerConnector@682c1e93{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-15 23:00:16,353] INFO Started @11557ms (org.eclipse.jetty.server.Server:379)
[2021-06-15 23:00:16,355] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-15 23:00:16,357] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-15 23:00:16,366] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-15 23:00:16,379] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 23:00:16,389] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 23:00:16,406] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 23:00:16,413] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	tasks.max = 1
	name = mongo-source-standalone
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:178)
[2021-06-15 23:00:16,459] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-15 23:00:16,461] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 23:00:16,463] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 23:00:16,502] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-15 23:00:16,506] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 23:00:16,512] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.ConnectorConfig:178)
[2021-06-15 23:00:17,757] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-15 23:00:18,125] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 23:00:18,379] INFO Opened connection [connectionId{localValue:1, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 23:00:18,460] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=32714600, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Tue Jun 15 23:00:10 GMT 2021, lastUpdateTimeNanos=103713892244071} (org.mongodb.driver.cluster:71)
[2021-06-15 23:00:18,843] INFO Opened connection [connectionId{localValue:2, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 23:00:19,943] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-15 23:00:19,959] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-15 23:00:19,960] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-15 23:00:20,378] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-15 23:00:20,391] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-15 23:00:20,393] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 23:00:20,401] INFO Resuming the change stream after the previous offset: {"_data": "8260C930FA000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-15 23:00:22,272] INFO Reflections took 9890 ms to scan 67 urls, producing 5722 keys and 43968 values  (org.reflections.Reflections:229)
[2021-06-15 23:00:22,956] INFO Reflections took 6437 ms to scan 67 urls, producing 5722 keys and 43968 values  (org.reflections.Reflections:229)
[2021-06-15 23:00:22,964] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 23:00:22,965] INFO Instantiated connector file-sink-standalone with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 23:00:22,966] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 23:00:22,968] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	tasks.max = 1
	topics = [gsr.connect.avro.test.fruits]
	name = file-sink-standalone
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:178)
[2021-06-15 23:00:22,974] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:178)
[2021-06-15 23:00:22,975] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 23:00:22,976] INFO Instantiated task file-sink-standalone-0 with version 0.10.0.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 23:00:23,008] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-15 23:00:23,027] INFO ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [127.0.0.1:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = connect-file-sink-standalone
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = earliest
 (org.apache.kafka.clients.consumer.ConsumerConfig:178)
[2021-06-15 23:00:23,113] INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-06-15 23:00:23,114] INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser:84)
[2021-06-15 23:00:23,119] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 23:00:23,125] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-15 23:00:23,488] WARN Error while fetching metadata with correlation id 1 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 23:00:23,544] WARN Error while fetching metadata with correlation id 2 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 23:00:23,662] WARN Error while fetching metadata with correlation id 4 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 23:00:23,842] WARN Error while fetching metadata with correlation id 6 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 23:00:24,034] WARN Error while fetching metadata with correlation id 8 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 23:00:24,147] WARN Error while fetching metadata with correlation id 10 : {gsr.connect.avro.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:600)
[2021-06-15 23:00:25,429] INFO Discovered coordinator localhost:9092 (id: 2147483646 rack: null) for group connect-file-sink-standalone. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:505)
[2021-06-15 23:00:25,432] INFO Revoking previously assigned partitions [] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:280)
[2021-06-15 23:00:25,433] INFO (Re-)joining group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:326)
[2021-06-15 23:00:25,570] INFO (Re-)joining group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:326)
[2021-06-15 23:00:25,821] INFO Successfully joined group connect-file-sink-standalone with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:434)
[2021-06-15 23:00:25,827] INFO Setting newly assigned partitions [gsr.connect.avro.test.fruits-0] for group connect-file-sink-standalone (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:219)
[2021-06-15 23:00:26,049] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 23:00:28,356] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 23:00:28,449] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 23:00:28,455] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 23:00:28,458] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:104)
[2021-06-15 23:00:28,460] INFO Schema Version Id received from the from schema registry: 1e8c757e-04fd-4dcf-8b11-824cc0645550 (com.amazonaws.services.schemaregistry.serializers.avro.AWSKafkaAvroSerializer:112)
[2021-06-15 23:00:32,986] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 23:00:36,541] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 43 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-15 23:00:43,019] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 23:00:52,997] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 23:01:02,995] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
