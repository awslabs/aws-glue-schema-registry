[2021-06-11 00:43:16,096] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	bootstrap.servers = [127.0.0.1:9092]
	cluster = connect
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = standalone.offsets
	rest.advertised.host.name = null
	rest.advertised.port = null
	rest.host.name = 127.0.0.1
	rest.port = 8086
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2021-06-11 00:43:17,377] INFO Logging initialized @3463ms (org.eclipse.jetty.util.log:186)
[2021-06-11 00:43:19,551] INFO JsonSchemaConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverterConfig:347)
[2021-06-11 00:43:19,556] INFO Configuring Glue Schema Registry Client using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:69)
[2021-06-11 00:43:19,620] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,621] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,628] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,635] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,636] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,638] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,641] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,643] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 00:43:19,645] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,648] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,649] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 00:43:19,651] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:19,656] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 00:43:23,194] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.GlueSchemaRegistryKafkaDeserializer:80)
[2021-06-11 00:43:23,205] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,207] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,209] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,211] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,212] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,214] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,216] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,218] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 00:43:23,221] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,223] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,225] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 00:43:23,229] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 00:43:23,232] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 00:43:23,327] INFO JsonSchemaDataConfig values: 
	connect.meta.data = true
	decimal.format = BASE64
	schemas.cache.config = 1000
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaDataConfig:347)
[2021-06-11 00:43:23,445] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-11 00:43:23,450] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-11 00:43:23,452] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-11 00:43:23,556] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2021-06-11 00:43:23,654] WARN [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 2147483647. (org.apache.kafka.clients.producer.KafkaProducer:499)
[2021-06-11 00:43:23,992] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-11 00:43:23,995] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-11 00:43:24,018] INFO Kafka startTimeMs: 1623372203976 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-11 00:43:24,040] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-11 00:43:24,056] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-11 00:43:24,062] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-11 00:43:24,065] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-11 00:43:25,559] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
[2021-06-11 00:43:30,238] INFO [Producer clientId=producer-1] Cluster ID: IDWiX4myTWK-aY3xTP58ZQ (org.apache.kafka.clients.Metadata:280)
Jun 11, 2021 12:43:32 AM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-11 00:43:32,832] INFO Started o.e.j.s.ServletContextHandler@e93f3d5{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-11 00:43:32,871] INFO Started ServerConnector@6dc1484{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-11 00:43:32,874] INFO Started @19004ms (org.eclipse.jetty.server.Server:379)
[2021-06-11 00:43:32,882] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-11 00:43:32,883] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-11 00:43:32,905] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-11 00:43:32,925] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 00:43:32,934] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 00:43:32,956] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 00:43:32,962] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2021-06-11 00:43:32,992] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-11 00:43:32,993] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 00:43:32,995] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 00:43:33,030] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 00:43:33,035] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-11 00:43:33,040] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-11 00:43:35,426] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-11 00:43:36,237] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 00:43:36,672] INFO Opened connection [connectionId{localValue:1, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 00:43:36,773] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 5]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=37237200, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Fri Jun 11 00:43:29 GMT 2021, lastUpdateTimeNanos=618338022809322} (org.mongodb.driver.cluster:71)
[2021-06-11 00:43:37,336] INFO Opened connection [connectionId{localValue:2, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 00:43:38,586] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-11 00:43:38,614] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-11 00:43:38,618] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-11 00:43:39,090] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-11 00:43:39,096] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-11 00:43:39,098] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 00:43:39,111] INFO Resuming the change stream after the previous offset: {"_data": "8260C2B1B1000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-11 00:43:40,355] INFO Reflections took 15788 ms to scan 65 urls, producing 5672 keys and 43601 values  (org.reflections.Reflections:229)
[2021-06-11 00:43:41,271] INFO Reflections took 8224 ms to scan 65 urls, producing 5672 keys and 43601 values  (org.reflections.Reflections:229)
[2021-06-11 00:43:41,279] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 00:43:41,282] INFO Instantiated connector file-sink-standalone with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 00:43:41,284] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 00:43:41,287] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
	topics = [gsr.connect.json.test.fruits]
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2021-06-11 00:43:41,297] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-11 00:43:41,299] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 00:43:41,301] INFO Instantiated task file-sink-standalone-0 with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 00:43:41,361] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-file-sink-standalone
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2021-06-11 00:43:41,625] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-11 00:43:41,627] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-11 00:43:41,629] INFO Kafka startTimeMs: 1623372221625 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-11 00:43:41,638] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 00:43:41,645] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Subscribed to topic(s): gsr.connect.json.test.fruits (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2021-06-11 00:43:41,656] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-11 00:43:41,860] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 2 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:41,866] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Cluster ID: IDWiX4myTWK-aY3xTP58ZQ (org.apache.kafka.clients.Metadata:280)
[2021-06-11 00:43:42,029] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 4 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:42,200] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 6 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:42,464] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 8 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:42,671] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 10 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:42,784] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 12 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:42,944] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 14 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:43,113] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 16 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:43,248] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 18 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 00:43:45,370] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 00:43:47,880] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2021-06-11 00:43:47,920] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-11 00:43:48,199] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2021-06-11 00:43:48,201] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-11 00:43:48,587] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Finished assignment for group at generation 1: {consumer-connect-file-sink-standalone-1-ae6a052f-029b-4d75-8061-7ea14975efd6=Assignment(partitions=[gsr.connect.json.test.fruits-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2021-06-11 00:43:48,944] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2021-06-11 00:43:49,042] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Adding newly assigned partitions: gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2021-06-11 00:43:49,236] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Found no committed offset for partition gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2021-06-11 00:43:49,373] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Resetting offset for partition gsr.connect.json.test.fruits-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2021-06-11 00:43:51,352] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 00:43:51,603] INFO Schema Version Id received from the from schema registry: 512b6456-1859-404b-bd57-202240971425 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 00:43:52,087] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 00:43:52,090] INFO Schema Version Id received from the from schema registry: 512b6456-1859-404b-bd57-202240971425 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 00:43:52,148] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 00:43:52,151] INFO Schema Version Id received from the from schema registry: 512b6456-1859-404b-bd57-202240971425 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 00:43:53,068] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 47 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-11 00:44:01,325] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 00:44:11,332] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:08:41,297] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	bootstrap.servers = [127.0.0.1:9092]
	cluster = connect
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = standalone.offsets
	rest.advertised.host.name = null
	rest.advertised.port = null
	rest.host.name = 127.0.0.1
	rest.port = 8086
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2021-06-11 18:08:41,826] INFO Logging initialized @1822ms (org.eclipse.jetty.util.log:186)
[2021-06-11 18:08:42,624] INFO JsonSchemaConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverterConfig:347)
[2021-06-11 18:08:42,625] INFO Configuring Glue Schema Registry Client using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:69)
[2021-06-11 18:08:42,640] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,641] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,643] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,652] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,653] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,654] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,656] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,657] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 18:08:42,658] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,659] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,660] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 18:08:42,661] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:42,664] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 18:08:44,354] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.GlueSchemaRegistryKafkaDeserializer:80)
[2021-06-11 18:08:44,359] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,361] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,362] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,363] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,364] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,365] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,366] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,367] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 18:08:44,368] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,369] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,370] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 18:08:44,371] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 18:08:44,373] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 18:08:44,426] INFO JsonSchemaDataConfig values: 
	connect.meta.data = true
	decimal.format = BASE64
	schemas.cache.config = 1000
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaDataConfig:347)
[2021-06-11 18:08:44,484] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-11 18:08:44,485] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-11 18:08:44,487] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-11 18:08:44,532] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2021-06-11 18:08:44,583] WARN [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 2147483647. (org.apache.kafka.clients.producer.KafkaProducer:499)
[2021-06-11 18:08:44,743] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-11 18:08:44,744] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-11 18:08:44,745] INFO Kafka startTimeMs: 1623434924739 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-11 18:08:44,750] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-11 18:08:44,757] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-11 18:08:44,768] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-11 18:08:44,769] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-11 18:08:45,575] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
[2021-06-11 18:08:46,999] INFO [Producer clientId=producer-1] Cluster ID: WUyX9NZJSNS0nSEcu_y_4Q (org.apache.kafka.clients.Metadata:280)
Jun 11, 2021 6:08:48 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-11 18:08:48,503] INFO Started o.e.j.s.ServletContextHandler@e93f3d5{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-11 18:08:48,533] INFO Started ServerConnector@67948e85{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-11 18:08:48,536] INFO Started @8540ms (org.eclipse.jetty.server.Server:379)
[2021-06-11 18:08:48,537] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-11 18:08:48,539] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-11 18:08:48,554] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-11 18:08:48,568] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 18:08:48,581] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 18:08:48,591] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 18:08:48,611] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2021-06-11 18:08:48,634] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-11 18:08:48,636] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 18:08:48,638] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 18:08:48,673] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-11 18:08:48,677] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 18:08:48,684] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-11 18:08:49,516] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-11 18:08:49,900] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 18:08:50,078] INFO Opened connection [connectionId{localValue:1, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 18:08:50,207] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=66934269, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Fri Jun 11 18:08:36 GMT 2021, lastUpdateTimeNanos=3744738069870} (org.mongodb.driver.cluster:71)
[2021-06-11 18:08:50,615] INFO Opened connection [connectionId{localValue:2, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 18:08:51,734] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-11 18:08:51,743] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-11 18:08:51,773] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-11 18:08:52,038] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-11 18:08:52,039] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-11 18:08:52,041] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 18:08:52,048] INFO Resuming the change stream after the previous offset: {"_data": "8260C3A6A4000000052B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-11 18:08:54,333] INFO Reflections took 9274 ms to scan 65 urls, producing 5634 keys and 43519 values  (org.reflections.Reflections:229)
[2021-06-11 18:08:55,351] INFO Reflections took 6632 ms to scan 65 urls, producing 5634 keys and 43519 values  (org.reflections.Reflections:229)
[2021-06-11 18:08:55,356] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 18:08:55,358] INFO Instantiated connector file-sink-standalone with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 18:08:55,359] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 18:08:55,361] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
	topics = [gsr.connect.json.test.fruits]
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2021-06-11 18:08:55,366] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-11 18:08:55,367] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 18:08:55,368] INFO Instantiated task file-sink-standalone-0 with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 18:08:55,414] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-file-sink-standalone
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2021-06-11 18:08:55,621] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-11 18:08:55,623] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-11 18:08:55,624] INFO Kafka startTimeMs: 1623434935621 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-11 18:08:55,635] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 18:08:55,642] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Subscribed to topic(s): gsr.connect.json.test.fruits (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2021-06-11 18:08:55,648] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-11 18:08:55,831] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 2 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 18:08:55,833] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Cluster ID: WUyX9NZJSNS0nSEcu_y_4Q (org.apache.kafka.clients.Metadata:280)
[2021-06-11 18:08:55,993] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 4 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 18:08:56,158] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 6 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 18:08:56,414] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 8 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 18:08:56,697] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 10 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 18:08:56,773] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 12 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 18:08:56,897] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 14 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 18:08:58,109] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 18:08:58,957] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2021-06-11 18:08:58,968] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-11 18:08:59,169] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2021-06-11 18:08:59,172] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-11 18:08:59,342] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Finished assignment for group at generation 1: {consumer-connect-file-sink-standalone-1-b6ccc9bb-238b-42d9-858c-1edcc4534d01=Assignment(partitions=[gsr.connect.json.test.fruits-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2021-06-11 18:08:59,636] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2021-06-11 18:08:59,681] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Adding newly assigned partitions: gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2021-06-11 18:08:59,735] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Found no committed offset for partition gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2021-06-11 18:08:59,775] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Resetting offset for partition gsr.connect.json.test.fruits-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2021-06-11 18:09:01,545] INFO Schema Version Id received from the from schema registry: 512b6456-1859-404b-bd57-202240971425 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 18:09:01,800] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 18:09:01,803] INFO Schema Version Id received from the from schema registry: 512b6456-1859-404b-bd57-202240971425 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 18:09:01,823] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 18:09:01,825] INFO Schema Version Id received from the from schema registry: 512b6456-1859-404b-bd57-202240971425 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 18:09:05,383] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:09:08,674] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 20 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-11 18:09:15,392] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:09:25,388] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 18:09:35,387] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 19:05:15,637] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	bootstrap.servers = [127.0.0.1:9092]
	cluster = connect
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = standalone.offsets
	rest.advertised.host.name = null
	rest.advertised.port = null
	rest.host.name = 127.0.0.1
	rest.port = 8086
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2021-06-11 19:05:16,123] INFO Logging initialized @1541ms (org.eclipse.jetty.util.log:186)
[2021-06-11 19:05:16,985] INFO JsonSchemaConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverterConfig:347)
[2021-06-11 19:05:16,987] INFO Configuring Glue Schema Registry Client using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:69)
[2021-06-11 19:05:17,011] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,013] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,015] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,019] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,020] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,021] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,022] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,024] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 19:05:17,025] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,026] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,027] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 19:05:17,029] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:17,032] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 19:05:18,650] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.GlueSchemaRegistryKafkaDeserializer:80)
[2021-06-11 19:05:18,661] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,663] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,667] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,667] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,669] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,670] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,671] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,672] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-11 19:05:18,675] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,677] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,678] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-11 19:05:18,680] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-11 19:05:18,683] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-11 19:05:18,731] INFO JsonSchemaDataConfig values: 
	connect.meta.data = true
	decimal.format = BASE64
	schemas.cache.config = 1000
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaDataConfig:347)
[2021-06-11 19:05:18,799] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-11 19:05:18,800] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-11 19:05:18,802] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-11 19:05:18,862] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2021-06-11 19:05:18,911] WARN [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 2147483647. (org.apache.kafka.clients.producer.KafkaProducer:499)
[2021-06-11 19:05:19,118] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-11 19:05:19,119] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-11 19:05:19,120] INFO Kafka startTimeMs: 1623438319112 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-11 19:05:19,127] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-11 19:05:19,133] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-11 19:05:19,136] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-11 19:05:19,138] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-11 19:05:19,955] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
[2021-06-11 19:05:22,105] INFO [Producer clientId=producer-1] Cluster ID: jr6giRoDQNKG5NgFRf0jJA (org.apache.kafka.clients.Metadata:280)
Jun 11, 2021 7:05:23 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-11 19:05:23,094] INFO Started o.e.j.s.ServletContextHandler@5942ee04{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-11 19:05:23,119] INFO Started ServerConnector@411291e5{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-11 19:05:23,121] INFO Started @8551ms (org.eclipse.jetty.server.Server:379)
[2021-06-11 19:05:23,123] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-11 19:05:23,124] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-11 19:05:23,130] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-11 19:05:23,139] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 19:05:23,145] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 19:05:23,159] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 19:05:23,162] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2021-06-11 19:05:23,194] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-11 19:05:23,196] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 19:05:23,198] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 19:05:23,213] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-11 19:05:23,265] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 19:05:23,278] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-11 19:05:23,919] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-11 19:05:24,230] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 19:05:24,359] INFO Opened connection [connectionId{localValue:1, serverValue:21}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 19:05:24,400] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15116768, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Fri Jun 11 19:05:21 GMT 2021, lastUpdateTimeNanos=7138954488622} (org.mongodb.driver.cluster:71)
[2021-06-11 19:05:24,766] INFO Opened connection [connectionId{localValue:2, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-11 19:05:25,885] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-11 19:05:25,895] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-11 19:05:25,896] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-11 19:05:26,167] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-11 19:05:26,168] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-11 19:05:26,172] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-11 19:05:26,184] INFO Resuming the change stream after the previous offset: {"_data": "8260C3B3F1000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-11 19:05:29,324] INFO Reflections took 9839 ms to scan 67 urls, producing 5634 keys and 43519 values  (org.reflections.Reflections:229)
[2021-06-11 19:05:29,573] INFO Reflections took 6274 ms to scan 67 urls, producing 5634 keys and 43519 values  (org.reflections.Reflections:229)
[2021-06-11 19:05:29,580] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-11 19:05:29,581] INFO Instantiated connector file-sink-standalone with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-11 19:05:29,582] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-11 19:05:29,584] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
	topics = [gsr.connect.json.test.fruits]
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2021-06-11 19:05:29,588] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-11 19:05:29,589] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-11 19:05:29,590] INFO Instantiated task file-sink-standalone-0 with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-11 19:05:29,612] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-file-sink-standalone
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2021-06-11 19:05:29,740] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-11 19:05:29,741] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-11 19:05:29,742] INFO Kafka startTimeMs: 1623438329740 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-11 19:05:29,754] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-11 19:05:29,761] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Subscribed to topic(s): gsr.connect.json.test.fruits (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2021-06-11 19:05:29,770] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-11 19:05:29,948] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 2 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 19:05:29,949] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Cluster ID: jr6giRoDQNKG5NgFRf0jJA (org.apache.kafka.clients.Metadata:280)
[2021-06-11 19:05:30,073] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 4 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 19:05:30,192] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 5 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 19:05:30,299] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 7 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 19:05:30,457] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 9 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 19:05:30,660] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 11 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 19:05:30,772] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 13 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-11 19:05:31,871] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2021-06-11 19:05:31,881] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-11 19:05:31,968] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Join group failed with org.apache.kafka.common.errors.CoordinatorLoadInProgressException: The coordinator is loading and hence can't process requests. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2021-06-11 19:05:32,070] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-11 19:05:32,116] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2021-06-11 19:05:32,119] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-11 19:05:32,238] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Finished assignment for group at generation 1: {consumer-connect-file-sink-standalone-1-53cb8d00-63b3-446a-a354-c5a958dc9bf7=Assignment(partitions=[gsr.connect.json.test.fruits-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2021-06-11 19:05:32,252] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 19:05:32,468] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2021-06-11 19:05:32,491] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Adding newly assigned partitions: gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2021-06-11 19:05:32,568] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Found no committed offset for partition gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2021-06-11 19:05:32,607] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Resetting offset for partition gsr.connect.json.test.fruits-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2021-06-11 19:05:35,759] INFO Registered the schema version with schema version id = 247de22a-96c9-4775-bb1e-ac38f69c4044 and with version number = 3 and status AVAILABLE (com.amazonaws.services.schemaregistry.common.AWSSchemaRegistryClient:341)
[2021-06-11 19:05:36,466] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 19:05:36,679] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 19:05:36,681] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 19:05:36,695] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-11 19:05:36,697] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-11 19:05:39,600] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 19:05:43,252] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 34 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-11 19:05:49,614] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 19:05:59,604] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-11 19:06:09,604] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 17:07:50,778] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	bootstrap.servers = [127.0.0.1:9092]
	cluster = connect
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = standalone.offsets
	rest.advertised.host.name = null
	rest.advertised.port = null
	rest.host.name = 127.0.0.1
	rest.port = 8086
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2021-06-15 17:07:51,626] INFO Logging initialized @2202ms (org.eclipse.jetty.util.log:186)
[2021-06-15 17:07:52,862] INFO JsonSchemaConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverterConfig:347)
[2021-06-15 17:07:52,866] INFO Configuring Glue Schema Registry Client using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:69)
[2021-06-15 17:07:52,895] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,897] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,900] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,905] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,906] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,907] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,909] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,911] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 17:07:52,912] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,914] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,915] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 17:07:52,916] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:52,918] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 17:07:55,321] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.GlueSchemaRegistryKafkaDeserializer:80)
[2021-06-15 17:07:55,326] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,328] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,329] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,330] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,331] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,333] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,334] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,335] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 17:07:55,336] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,337] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,339] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 17:07:55,342] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 17:07:55,344] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 17:07:55,405] INFO JsonSchemaDataConfig values: 
	connect.meta.data = true
	decimal.format = BASE64
	schemas.cache.config = 1000
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaDataConfig:347)
[2021-06-15 17:07:55,482] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-15 17:07:55,483] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-15 17:07:55,484] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-15 17:07:55,584] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2021-06-15 17:07:55,662] WARN [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 2147483647. (org.apache.kafka.clients.producer.KafkaProducer:499)
[2021-06-15 17:07:55,923] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-15 17:07:55,925] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-15 17:07:55,926] INFO Kafka startTimeMs: 1623776875908 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-15 17:07:55,935] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-15 17:07:55,955] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-15 17:07:55,973] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-15 17:07:55,974] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-15 17:07:57,239] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
[2021-06-15 17:07:59,649] INFO [Producer clientId=producer-1] Cluster ID: W4iYDW0MTFiUZxMaRfwSMg (org.apache.kafka.clients.Metadata:280)
Jun 15, 2021 5:08:01 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-15 17:08:01,914] INFO Started o.e.j.s.ServletContextHandler@5942ee04{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-15 17:08:01,950] INFO Started ServerConnector@e2669ae{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-15 17:08:01,952] INFO Started @12539ms (org.eclipse.jetty.server.Server:379)
[2021-06-15 17:08:01,953] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-15 17:08:01,955] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-15 17:08:01,975] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-15 17:08:01,986] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 17:08:01,993] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 17:08:02,022] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 17:08:02,025] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2021-06-15 17:08:02,057] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-15 17:08:02,059] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 17:08:02,060] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 17:08:02,097] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-15 17:08:02,103] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 17:08:02,106] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-15 17:08:03,824] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-15 17:08:04,512] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 17:08:04,567] INFO Opened connection [connectionId{localValue:1, serverValue:21}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 17:08:04,664] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=37684800, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Tue Jun 15 17:07:55 GMT 2021, lastUpdateTimeNanos=82567190253771} (org.mongodb.driver.cluster:71)
[2021-06-15 17:08:05,240] INFO Opened connection [connectionId{localValue:2, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 17:08:06,507] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-15 17:08:06,531] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-15 17:08:06,534] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-15 17:08:07,157] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-15 17:08:07,168] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-15 17:08:07,181] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 17:08:07,197] INFO Resuming the change stream after the previous offset: {"_data": "8260C8DE75000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-15 17:08:10,215] INFO Reflections took 13886 ms to scan 67 urls, producing 5647 keys and 43624 values  (org.reflections.Reflections:229)
[2021-06-15 17:08:10,984] INFO Reflections took 8871 ms to scan 67 urls, producing 5647 keys and 43624 values  (org.reflections.Reflections:229)
[2021-06-15 17:08:10,993] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 17:08:10,995] INFO Instantiated connector file-sink-standalone with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 17:08:10,996] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 17:08:10,997] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
	topics = [gsr.connect.json.test.fruits]
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2021-06-15 17:08:11,012] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-15 17:08:11,014] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 17:08:11,016] INFO Instantiated task file-sink-standalone-0 with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 17:08:11,078] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-file-sink-standalone
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2021-06-15 17:08:11,298] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-15 17:08:11,299] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-15 17:08:11,300] INFO Kafka startTimeMs: 1623776891298 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-15 17:08:11,308] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 17:08:11,313] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Subscribed to topic(s): gsr.connect.json.test.fruits (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2021-06-15 17:08:11,318] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-15 17:08:11,531] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 2 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:11,535] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Cluster ID: W4iYDW0MTFiUZxMaRfwSMg (org.apache.kafka.clients.Metadata:280)
[2021-06-15 17:08:11,867] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 4 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:11,980] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 5 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:12,091] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 7 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:12,291] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 9 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:12,521] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 11 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:12,654] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 13 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:12,802] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 15 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:12,863] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 17:08:12,936] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 17 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:13,091] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 19 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 17:08:16,907] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2021-06-15 17:08:16,928] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-15 17:08:17,057] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2021-06-15 17:08:17,059] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-15 17:08:17,172] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Finished assignment for group at generation 1: {consumer-connect-file-sink-standalone-1-2c1dc2e5-1970-4d9f-80d1-e46c5dd28ad5=Assignment(partitions=[gsr.connect.json.test.fruits-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2021-06-15 17:08:17,332] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2021-06-15 17:08:17,363] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Adding newly assigned partitions: gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2021-06-15 17:08:17,414] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Found no committed offset for partition gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2021-06-15 17:08:17,474] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Resetting offset for partition gsr.connect.json.test.fruits-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2021-06-15 17:08:18,380] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 17:08:18,858] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 17:08:18,867] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 17:08:18,881] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 17:08:18,883] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 17:08:21,033] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 17:08:22,088] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 36 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-15 17:08:31,101] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 17:08:41,038] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 18:12:41,369] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	bootstrap.servers = [127.0.0.1:9092]
	cluster = connect
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = standalone.offsets
	rest.advertised.host.name = null
	rest.advertised.port = null
	rest.host.name = 127.0.0.1
	rest.port = 8086
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2021-06-15 18:12:42,458] INFO Logging initialized @2884ms (org.eclipse.jetty.util.log:186)
[2021-06-15 18:12:44,120] INFO JsonSchemaConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverterConfig:347)
[2021-06-15 18:12:44,130] INFO Configuring Glue Schema Registry Client using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:69)
[2021-06-15 18:12:44,181] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,183] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,188] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,197] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,198] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,201] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,203] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,205] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 18:12:44,208] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,210] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,211] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 18:12:44,213] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:44,224] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 18:12:47,702] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.GlueSchemaRegistryKafkaDeserializer:80)
[2021-06-15 18:12:47,708] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,709] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,710] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,711] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,713] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,714] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,715] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,716] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 18:12:47,718] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,719] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,721] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 18:12:47,722] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 18:12:47,724] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 18:12:47,891] INFO JsonSchemaDataConfig values: 
	connect.meta.data = true
	decimal.format = BASE64
	schemas.cache.config = 1000
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaDataConfig:347)
[2021-06-15 18:12:48,074] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-15 18:12:48,075] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-15 18:12:48,077] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-15 18:12:48,192] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2021-06-15 18:12:48,281] WARN [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 2147483647. (org.apache.kafka.clients.producer.KafkaProducer:499)
[2021-06-15 18:12:48,500] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-15 18:12:48,501] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-15 18:12:48,503] INFO Kafka startTimeMs: 1623780768492 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-15 18:12:48,509] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-15 18:12:48,521] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-15 18:12:48,527] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-15 18:12:48,528] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-15 18:12:49,877] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
[2021-06-15 18:12:53,979] INFO [Producer clientId=producer-1] Cluster ID: TWZCFXsKQOiXPDQ12kO96Q (org.apache.kafka.clients.Metadata:280)
Jun 15, 2021 6:12:54 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-15 18:12:54,935] INFO Started o.e.j.s.ServletContextHandler@5942ee04{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-15 18:12:54,973] INFO Started ServerConnector@411291e5{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-15 18:12:54,974] INFO Started @15413ms (org.eclipse.jetty.server.Server:379)
[2021-06-15 18:12:54,976] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-15 18:12:54,977] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-15 18:12:54,989] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-15 18:12:55,004] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 18:12:55,014] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 18:12:55,024] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 18:12:55,028] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2021-06-15 18:12:55,096] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-15 18:12:55,097] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 18:12:55,098] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 18:12:55,125] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 18:12:55,130] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-15 18:12:55,130] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-15 18:12:56,841] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-15 18:12:57,282] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 18:12:57,521] INFO Opened connection [connectionId{localValue:1, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 18:12:57,570] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=22857500, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Tue Jun 15 18:12:52 GMT 2021, lastUpdateTimeNanos=86464627711871} (org.mongodb.driver.cluster:71)
[2021-06-15 18:12:58,046] INFO Opened connection [connectionId{localValue:2, serverValue:24}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 18:12:59,202] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-15 18:12:59,213] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-15 18:12:59,217] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-15 18:12:59,617] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-15 18:12:59,619] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-15 18:12:59,621] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 18:12:59,636] INFO Resuming the change stream after the previous offset: {"_data": "8260C8EDA4000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-15 18:13:00,745] INFO Reflections took 11768 ms to scan 67 urls, producing 5647 keys and 43624 values  (org.reflections.Reflections:229)
[2021-06-15 18:13:01,888] INFO Reflections took 6732 ms to scan 67 urls, producing 5647 keys and 43624 values  (org.reflections.Reflections:229)
[2021-06-15 18:13:01,895] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 18:13:01,897] INFO Instantiated connector file-sink-standalone with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 18:13:01,898] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 18:13:01,900] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
	topics = [gsr.connect.json.test.fruits]
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2021-06-15 18:13:01,908] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-15 18:13:01,910] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 18:13:01,911] INFO Instantiated task file-sink-standalone-0 with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 18:13:01,951] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-file-sink-standalone
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2021-06-15 18:13:02,129] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-15 18:13:02,130] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-15 18:13:02,131] INFO Kafka startTimeMs: 1623780782129 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-15 18:13:02,139] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 18:13:02,142] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Subscribed to topic(s): gsr.connect.json.test.fruits (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2021-06-15 18:13:02,148] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-15 18:13:02,295] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 2 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 18:13:02,297] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Cluster ID: TWZCFXsKQOiXPDQ12kO96Q (org.apache.kafka.clients.Metadata:280)
[2021-06-15 18:13:02,413] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 4 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 18:13:02,598] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 6 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 18:13:02,814] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 8 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 18:13:02,925] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 10 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 18:13:04,205] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2021-06-15 18:13:04,225] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-15 18:13:04,313] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2021-06-15 18:13:04,315] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-15 18:13:04,392] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Finished assignment for group at generation 1: {consumer-connect-file-sink-standalone-1-d17ed83e-a4a6-4a65-9d8d-f976b88ff0eb=Assignment(partitions=[gsr.connect.json.test.fruits-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2021-06-15 18:13:04,564] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2021-06-15 18:13:04,587] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Adding newly assigned partitions: gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2021-06-15 18:13:04,647] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Found no committed offset for partition gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2021-06-15 18:13:04,700] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Resetting offset for partition gsr.connect.json.test.fruits-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2021-06-15 18:13:05,575] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 18:13:08,714] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 18:13:09,026] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 18:13:09,031] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 18:13:09,050] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 18:13:09,053] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 18:13:11,925] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 18:13:15,127] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 48 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-15 18:13:21,941] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 18:13:31,929] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 23:01:57,537] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	bootstrap.servers = [127.0.0.1:9092]
	cluster = connect
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = standalone.offsets
	rest.advertised.host.name = null
	rest.advertised.port = null
	rest.host.name = 127.0.0.1
	rest.port = 8086
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2021-06-15 23:01:58,482] INFO Logging initialized @2765ms (org.eclipse.jetty.util.log:186)
[2021-06-15 23:01:59,932] INFO JsonSchemaConverterConfig values: 
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaConverterConfig:347)
[2021-06-15 23:01:59,934] INFO Configuring Glue Schema Registry Client using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:69)
[2021-06-15 23:01:59,961] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,963] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,967] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,971] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,973] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,974] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,976] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,977] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 23:01:59,979] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,981] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,983] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 23:01:59,984] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:01:59,988] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 23:02:02,966] INFO Configuring Amazon Glue Schema Registry Service using these properties: {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.deserializers.GlueSchemaRegistryKafkaDeserializer:80)
[2021-06-15 23:02:02,972] INFO registry.name key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,973] INFO description key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,974] INFO compatibility key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,975] INFO compression key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,977] INFO jacksonSerializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,977] INFO jacksonDeserializationFeatures key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,979] INFO tags key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,981] INFO Tags value is not defined in the properties. No tags are assigned (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:220)
[2021-06-15 23:02:02,984] INFO metadata key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,985] INFO cacheSize key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,986] INFO Cache Size is not found, using default 200 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:174)
[2021-06-15 23:02:02,987] INFO timeToLiveMillis key is not present in the configs {endpoint=https://glue-gamma.us-east-1.amazonaws.com, schemaAutoRegistrationEnabled=true, dataFormat=JSON, region=us-east-1, avroRecordType=GENERIC_RECORD, schemas.enable=true} (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:267)
[2021-06-15 23:02:02,990] INFO Cache Time to live is not found, using default 86400000 (com.amazonaws.services.schemaregistry.common.configs.GlueSchemaRegistryConfiguration:188)
[2021-06-15 23:02:03,081] INFO JsonSchemaDataConfig values: 
	connect.meta.data = true
	decimal.format = BASE64
	schemas.cache.config = 1000
 (com.amazonaws.services.schemaregistry.kafkaconnect.jsonschema.JsonSchemaDataConfig:347)
[2021-06-15 23:02:03,210] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:52)
[2021-06-15 23:02:03,211] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:71)
[2021-06-15 23:02:03,212] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:102)
[2021-06-15 23:02:03,296] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2021-06-15 23:02:03,395] WARN [Producer clientId=producer-1] delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms. Setting it to 2147483647. (org.apache.kafka.clients.producer.KafkaProducer:499)
[2021-06-15 23:02:03,729] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-15 23:02:03,732] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-15 23:02:03,735] INFO Kafka startTimeMs: 1623798123720 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-15 23:02:03,752] INFO Starting FileOffsetBackingStore with file standalone.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:60)
[2021-06-15 23:02:03,763] INFO Worker started (org.apache.kafka.connect.runtime.Worker:124)
[2021-06-15 23:02:03,770] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:73)
[2021-06-15 23:02:03,772] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:98)
[2021-06-15 23:02:04,959] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server:327)
[2021-06-15 23:02:07,366] INFO [Producer clientId=producer-1] Cluster ID: QAugMeVGSF2hi5tEw_wpcg (org.apache.kafka.clients.Metadata:280)
Jun 15, 2021 11:02:09 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

[2021-06-15 23:02:09,887] INFO Started o.e.j.s.ServletContextHandler@5942ee04{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[2021-06-15 23:02:09,955] INFO Started ServerConnector@411291e5{HTTP/1.1}{127.0.0.1:8086} (org.eclipse.jetty.server.ServerConnector:266)
[2021-06-15 23:02:09,959] INFO Started @14290ms (org.eclipse.jetty.server.Server:379)
[2021-06-15 23:02:09,965] INFO REST server listening at http://127.0.0.1:8086/, advertising URL http://127.0.0.1:8086/ (org.apache.kafka.connect.runtime.rest.RestServer:150)
[2021-06-15 23:02:09,967] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:58)
[2021-06-15 23:02:09,982] INFO ConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-15 23:02:10,010] INFO Creating connector mongo-source-standalone of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 23:02:10,023] INFO Instantiated connector mongo-source-standalone with version 1.3.0 of type com.mongodb.kafka.connect.MongoSourceConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 23:02:10,076] INFO Finished creating connector mongo-source-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 23:02:10,083] INFO SourceConnectorConfig values: 
	connector.class = com.mongodb.kafka.connect.MongoSourceConnector
	name = mongo-source-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2021-06-15 23:02:10,142] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.source.MongoSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-15 23:02:10,147] INFO Creating task mongo-source-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 23:02:10,150] INFO Instantiated task mongo-source-standalone-0 with version 1.3.0 of type com.mongodb.kafka.connect.source.MongoSourceTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 23:02:10,192] INFO Starting MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:161)
[2021-06-15 23:02:10,213] INFO Created connector mongo-source-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 23:02:10,217] INFO ConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2021-06-15 23:02:12,382] INFO Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500} (org.mongodb.driver.cluster:71)
[2021-06-15 23:02:12,867] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 23:02:13,167] INFO Opened connection [connectionId{localValue:1, serverValue:22}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 23:02:13,267] INFO Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, version=ServerVersion{versionList=[4, 4, 6]}, minWireVersion=0, maxWireVersion=9, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=40634800, setName='repl-set', canonicalAddress=mongo1:27017, hosts=[mongo1:27017], passives=[mongo2:27018, mongo3:27019], arbiters=[], primary='mongo1:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, lastWriteDate=Tue Jun 15 23:02:11 GMT 2021, lastUpdateTimeNanos=103828826555971} (org.mongodb.driver.cluster:71)
[2021-06-15 23:02:13,725] INFO Opened connection [connectionId{localValue:2, serverValue:23}] to 127.0.0.1:27017 (org.mongodb.driver.connection:71)
[2021-06-15 23:02:14,970] INFO Copying existing data on the following namespaces: [test.fruits] (com.mongodb.kafka.connect.source.MongoCopyDataManager:78)
[2021-06-15 23:02:15,020] INFO Started MongoDB source task (com.mongodb.kafka.connect.source.MongoSourceTask:183)
[2021-06-15 23:02:15,027] INFO Source task WorkerSourceTask{id=mongo-source-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:138)
[2021-06-15 23:02:15,519] INFO Shutting down executors (com.mongodb.kafka.connect.source.MongoSourceTask:563)
[2021-06-15 23:02:15,521] INFO Finished copying existing data from the collection(s). (com.mongodb.kafka.connect.source.MongoSourceTask:570)
[2021-06-15 23:02:15,522] INFO Watching for collection changes on 'test.fruits' (com.mongodb.kafka.connect.source.MongoSourceTask:624)
[2021-06-15 23:02:15,540] INFO Resuming the change stream after the previous offset: {"_data": "8260C93173000000022B0229296E04"} (com.mongodb.kafka.connect.source.MongoSourceTask:374)
[2021-06-15 23:02:17,059] INFO Reflections took 12732 ms to scan 67 urls, producing 5647 keys and 43624 values  (org.reflections.Reflections:229)
[2021-06-15 23:02:18,019] INFO Reflections took 7779 ms to scan 67 urls, producing 5647 keys and 43624 values  (org.reflections.Reflections:229)
[2021-06-15 23:02:18,027] INFO Creating connector file-sink-standalone of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:168)
[2021-06-15 23:02:18,029] INFO Instantiated connector file-sink-standalone with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkConnector (org.apache.kafka.connect.runtime.Worker:176)
[2021-06-15 23:02:18,031] INFO Finished creating connector file-sink-standalone (org.apache.kafka.connect.runtime.Worker:181)
[2021-06-15 23:02:18,033] INFO SinkConnectorConfig values: 
	connector.class = FileStreamSink
	name = file-sink-standalone
	tasks.max = 1
	topics = [gsr.connect.json.test.fruits]
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2021-06-15 23:02:18,045] INFO TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2021-06-15 23:02:18,046] INFO Creating task file-sink-standalone-0 (org.apache.kafka.connect.runtime.Worker:315)
[2021-06-15 23:02:18,048] INFO Instantiated task file-sink-standalone-0 with version 2.5.0 of type org.apache.kafka.connect.file.FileStreamSinkTask (org.apache.kafka.connect.runtime.Worker:326)
[2021-06-15 23:02:18,093] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-file-sink-standalone
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2021-06-15 23:02:18,298] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2021-06-15 23:02:18,300] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2021-06-15 23:02:18,301] INFO Kafka startTimeMs: 1623798138298 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-06-15 23:02:18,306] INFO Created connector file-sink-standalone (org.apache.kafka.connect.cli.ConnectStandalone:91)
[2021-06-15 23:02:18,310] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Subscribed to topic(s): gsr.connect.json.test.fruits (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2021-06-15 23:02:18,318] INFO Sink task WorkerSinkTask{id=file-sink-standalone-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:208)
[2021-06-15 23:02:18,451] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 2 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 23:02:18,453] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Cluster ID: QAugMeVGSF2hi5tEw_wpcg (org.apache.kafka.clients.Metadata:280)
[2021-06-15 23:02:18,565] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 4 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 23:02:18,734] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 6 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 23:02:18,885] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 8 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 23:02:19,195] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 10 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 23:02:19,313] WARN [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Error while fetching metadata with correlation id 12 : {gsr.connect.json.test.fruits=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2021-06-15 23:02:20,794] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2021-06-15 23:02:20,818] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-15 23:02:20,909] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2021-06-15 23:02:20,910] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2021-06-15 23:02:20,999] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Finished assignment for group at generation 1: {consumer-connect-file-sink-standalone-1-cb8e2a43-bd70-48cb-ac89-d95380245e23=Assignment(partitions=[gsr.connect.json.test.fruits-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2021-06-15 23:02:21,218] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2021-06-15 23:02:21,285] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Adding newly assigned partitions: gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2021-06-15 23:02:21,384] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Found no committed offset for partition gsr.connect.json.test.fruits-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2021-06-15 23:02:21,469] INFO [Consumer clientId=consumer-connect-file-sink-standalone-1, groupId=connect-file-sink-standalone] Resetting offset for partition gsr.connect.json.test.fruits-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2021-06-15 23:02:21,513] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 23:02:25,514] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 23:02:25,947] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 23:02:25,960] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 23:02:26,007] INFO Schema Version Id is null. Trying to register the schema. (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:101)
[2021-06-15 23:02:26,015] INFO Schema Version Id received from the from schema registry: 247de22a-96c9-4775-bb1e-ac38f69c4044 (com.amazonaws.services.schemaregistry.serializers.GlueSchemaRegistryKafkaSerializer:109)
[2021-06-15 23:02:28,066] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 23:02:30,222] INFO Finished WorkerSourceTask{id=mongo-source-standalone-0} commitOffsets successfully in 32 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:356)
[2021-06-15 23:02:38,085] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
[2021-06-15 23:02:48,071] INFO WorkerSinkTask{id=file-sink-standalone-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask:244)
